{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bec1b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/breachcompilation.csv', header=None)\n",
    "passwords = df[0].values  # Get passwords from first column\n",
    "\n",
    "# Reduce dataset to 25k samples\n",
    "np.random.seed(42)\n",
    "passwords = np.random.choice(passwords, size=30000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76c43d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char_type(char):\n",
    "    common_lower = 'esaitnruol'\n",
    "    common_upper = 'ESAITNRUOL'\n",
    "    numbers = '0123456789'\n",
    "    common_special = '><-?.!/,%@&'\n",
    "    \n",
    "    if char in common_lower:\n",
    "        return '1'\n",
    "    elif char.islower():\n",
    "        return '2'\n",
    "    elif char in common_upper:\n",
    "        return '3'\n",
    "    elif char.isupper():\n",
    "        return '4'\n",
    "    elif char in numbers:\n",
    "        return '5'\n",
    "    elif char in common_special:\n",
    "        return '6'\n",
    "    elif not char.isalnum():\n",
    "        return '7'\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "def mask_password(password):\n",
    "    return ''.join(get_char_type(c) for c in str(password))\n",
    "\n",
    "# Create masked versions of passwords\n",
    "masked_passwords = np.array([mask_password(p) for p in passwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d189c586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(masked_pass):\n",
    "    # Get the maximum length in the dataset\n",
    "    max_len = 30\n",
    "    \n",
    "    # Initialize a numpy array with zeros\n",
    "    X = np.zeros((len(masked_pass), max_len))\n",
    "    \n",
    "    # Fill the array with the masked password values\n",
    "    for i, password in enumerate(masked_pass):\n",
    "        # Pad or truncate password to max_len\n",
    "        padded = password.ljust(max_len, '0')\n",
    "        # Convert characters to integers and store in array\n",
    "        for j, char in enumerate(padded[:max_len]):\n",
    "            X[i, j] = int(char)\n",
    "    \n",
    "    return X\n",
    "\n",
    "# Create feature matrix\n",
    "X = create_features(masked_passwords)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "155775b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.5648600699718502\n"
     ]
    }
   ],
   "source": [
    "# Perform clustering\n",
    "clustering = AgglomerativeClustering(\n",
    "    n_clusters=None,\n",
    "    distance_threshold=8,\n",
    "    linkage='ward'\n",
    ")\n",
    "clusters = clustering.fit(X_scaled)\n",
    "\n",
    "# Get cluster centers\n",
    "cluster_centers = []\n",
    "for i in range(clustering.n_clusters_):\n",
    "    mask = clusters.labels_ == i\n",
    "    cluster_centers.append(np.mean(X_scaled[mask], axis=0))\n",
    "cluster_centers = np.array(cluster_centers)\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Calculate silhouette score\n",
    "silhouette_avg = silhouette_score(X_scaled, clusters.labels_)\n",
    "print(f\"Silhouette Score: {silhouette_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc1104f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_password_similarity(password, clustering, X_scaled, scaler):\n",
    "    \"\"\"\n",
    "    Compute similarity percentage between input password and breached password clusters.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    password : str\n",
    "        Input password to check\n",
    "    clustering : AgglomerativeClustering\n",
    "        Fitted clustering model\n",
    "    X_scaled : array\n",
    "        Scaled feature matrix used for clustering\n",
    "    scaler : StandardScaler\n",
    "        Fitted scaler used to transform features\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Similarity percentage (0-100)\n",
    "    int\n",
    "        Most similar cluster ID\n",
    "    \"\"\"\n",
    "    # Convert password to masked version\n",
    "    masked_pwd = mask_password(password)\n",
    "    \n",
    "    # Create features for the single password\n",
    "    X_new = create_features([masked_pwd])\n",
    "    \n",
    "    # Scale the features using the same scaler\n",
    "    X_new_scaled = scaler.transform(X_new)\n",
    "    \n",
    "    # Calculate distances to all cluster centers\n",
    "    distances = []\n",
    "    for i in range(clustering.n_clusters_):\n",
    "        mask = clustering.labels_ == i\n",
    "        center = np.mean(X_scaled[mask], axis=0)\n",
    "        dist = np.linalg.norm(X_new_scaled - center)\n",
    "        distances.append(dist)\n",
    "    \n",
    "    # Convert distance to similarity percentage\n",
    "    min_dist = min(distances)\n",
    "    closest_cluster = np.argmin(distances)\n",
    "    \n",
    "    # Use a steeper exponential decay with normalization\n",
    "    max_reasonable_dist = 10.0  # May need to adjust this based on data\n",
    "    normalized_dist = min_dist / max_reasonable_dist\n",
    "    similarity = 100 * np.exp(-2 * normalized_dist)  # Steeper decay with factor -2\n",
    "    \n",
    "    # Clip to ensure we don't exceed 100%\n",
    "    similarity = min(similarity, 100.0)\n",
    "    \n",
    "    return similarity, closest_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1f4c3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Password similarity: 85.38%\n",
      "Most similar cluster: 175\n"
     ]
    }
   ],
   "source": [
    "test_password = \"ikhwan2002\"\n",
    "similarity, cluster = compute_password_similarity(\n",
    "    test_password, \n",
    "    clustering,\n",
    "    X_scaled,\n",
    "    scaler\n",
    ")\n",
    "\n",
    "print(f\"Password similarity: {similarity:.2f}%\")\n",
    "print(f\"Most similar cluster: {cluster}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58899e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496\n",
      "Model saved to model3.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "print(clustering.n_clusters_)\n",
    "# Save both the clustering model and scaler\n",
    "joblib.dump({\n",
    "    'clustering': clustering,\n",
    "    'scaler': scaler,\n",
    "    'X_scaled': X_scaled\n",
    "}, 'model3.pkl')\n",
    "\n",
    "print(\"Model saved to model3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f90ee94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering model loaded: AgglomerativeClustering(distance_threshold=8, n_clusters=None)\n",
      "Scaler loaded: StandardScaler()\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the model and scaler\n",
    "loaded_model = joblib.load('model3.pkl')\n",
    "clustering = loaded_model['clustering']\n",
    "scaler = loaded_model['scaler']\n",
    "\n",
    "# Check the loaded model and scaler\n",
    "print(\"Clustering model loaded:\", clustering)\n",
    "print(\"Scaler loaded:\", scaler)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
